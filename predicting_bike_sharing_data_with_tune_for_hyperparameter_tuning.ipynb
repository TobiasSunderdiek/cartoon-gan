{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predicting_bike_sharing_data_with_tune_for_hyperparameter_tuning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TobiasSunderdiek/cartoon-gan/blob/master/predicting_bike_sharing_data_with_tune_for_hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z0eKFKr8neG",
        "colab_type": "text"
      },
      "source": [
        "# Predicting bike sharing data with tune for hyperparameter tuning\n",
        "\n",
        "\n",
        "This notebook is based on the udacity deep learning nanodegree project for predicting bike sharing data, which can be found here:\n",
        "\n",
        "https://github.com/udacity/deep-learning-v2-pytorch/blob/master/project-bikesharing/Predicting_bike_sharing_data.ipynb\n",
        "\n",
        "I use the udacity implementation as a starting point for a self-learning project in which I try to build a variation where the model is a fcn and the hyperparameter tuning is done with tune[1].\n",
        "\n",
        "[1] https://ray.readthedocs.io/en/latest/tune.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4GQQ0xBKBGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "338ad57d-191b-4fdc-8ae2-bb36cc27006a"
      },
      "source": [
        "# notebook settings\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<style>.container { width:80% !important; }</style>'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb5V5Sb09V4W",
        "colab_type": "text"
      },
      "source": [
        "## Loading dataset from github\n",
        "The original dataset is located here:\n",
        "\n",
        "https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/project-bikesharing/Bike-Sharing-Dataset/hour.csv\n",
        "\n",
        "which originaly came from [1].\n",
        "\n",
        "[1] Fanaee-T, Hadi, and Gama, Joao, \"Event labeling combining ensemble detectors and background knowledge\", Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg, doi:10.1007/s13748-013-0040-3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT4j5Qg2o9Yg",
        "colab_type": "code",
        "outputId": "e9b5c38f-c0c1-43ff-956d-8e2a7ca0ef4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Fetch a single file using the raw GitHub URL.\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/project-bikesharing/Bike-Sharing-Dataset/hour.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1129k  100 1129k    0     0  3679k      0 --:--:-- --:--:-- --:--:-- 3679k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMh2OG7rGpx",
        "colab_type": "code",
        "outputId": "b081f1bc-1c4f-43ca-d995-04625c2d7fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "rides = pd.read_csv(\"/content/hour.csv\")\n",
        "rides_origin = rides\n",
        "rides.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "segnb5Shu-1S",
        "colab_type": "text"
      },
      "source": [
        "### Convert data\n",
        "- hot-encode categorical features *season*, *weathersit*, *mnth*, *hr*, *weekday* and drop origin of this features\n",
        "- drop fields *instant*, *dteday*, *atemp* and *workingday* as in the udacity project\n",
        "- additionally drop fields *casual* and *registered*, focus on overall output *cnt*\n",
        "- shift and scale continuous features *cnt*, *temp*, *hum*, *windspeed* so they have zero mean and standard deviation of 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rqqljiastz8",
        "colab_type": "code",
        "outputId": "e655f17f-4d23-41d8-807a-10d97e8fdfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "for feature in ['season', 'weathersit', 'mnth', 'hr', 'weekday']:\n",
        "  hot_encoded_features = pd.get_dummies(rides[feature], prefix=feature, drop_first=False)\n",
        "  rides = pd.concat([rides, hot_encoded_features], axis=1)\n",
        "  rides = rides.drop(feature, axis=1)\n",
        "rides = rides.drop(['instant', 'dteday', 'atemp', 'workingday', 'casual', 'registered'], axis=1)\n",
        "\n",
        "feature_scaling_store = {}\n",
        "\n",
        "for feature in ['cnt', 'temp', 'hum', 'windspeed']:\n",
        "  mean, std = rides[feature].mean(), rides[feature].std()\n",
        "  feature_scaling_store[feature] = [mean, std]\n",
        "  rides.loc[:, feature] = (rides[feature] - mean) / std\n",
        "\n",
        "rides.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>temp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>cnt</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>weathersit_1</th>\n",
              "      <th>weathersit_2</th>\n",
              "      <th>weathersit_3</th>\n",
              "      <th>weathersit_4</th>\n",
              "      <th>mnth_1</th>\n",
              "      <th>mnth_2</th>\n",
              "      <th>mnth_3</th>\n",
              "      <th>mnth_4</th>\n",
              "      <th>mnth_5</th>\n",
              "      <th>mnth_6</th>\n",
              "      <th>mnth_7</th>\n",
              "      <th>mnth_8</th>\n",
              "      <th>mnth_9</th>\n",
              "      <th>mnth_10</th>\n",
              "      <th>mnth_11</th>\n",
              "      <th>mnth_12</th>\n",
              "      <th>hr_0</th>\n",
              "      <th>hr_1</th>\n",
              "      <th>hr_2</th>\n",
              "      <th>hr_3</th>\n",
              "      <th>hr_4</th>\n",
              "      <th>hr_5</th>\n",
              "      <th>hr_6</th>\n",
              "      <th>hr_7</th>\n",
              "      <th>hr_8</th>\n",
              "      <th>hr_9</th>\n",
              "      <th>hr_10</th>\n",
              "      <th>hr_11</th>\n",
              "      <th>hr_12</th>\n",
              "      <th>hr_13</th>\n",
              "      <th>hr_14</th>\n",
              "      <th>hr_15</th>\n",
              "      <th>hr_16</th>\n",
              "      <th>hr_17</th>\n",
              "      <th>hr_18</th>\n",
              "      <th>hr_19</th>\n",
              "      <th>hr_20</th>\n",
              "      <th>hr_21</th>\n",
              "      <th>hr_22</th>\n",
              "      <th>hr_23</th>\n",
              "      <th>weekday_0</th>\n",
              "      <th>weekday_1</th>\n",
              "      <th>weekday_2</th>\n",
              "      <th>weekday_3</th>\n",
              "      <th>weekday_4</th>\n",
              "      <th>weekday_5</th>\n",
              "      <th>weekday_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334609</td>\n",
              "      <td>0.947345</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.956312</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438475</td>\n",
              "      <td>0.895513</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.823998</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.438475</td>\n",
              "      <td>0.895513</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.868103</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334609</td>\n",
              "      <td>0.636351</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-0.972851</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.334609</td>\n",
              "      <td>0.636351</td>\n",
              "      <td>-1.553844</td>\n",
              "      <td>-1.039008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   yr  holiday      temp       hum  ...  weekday_3  weekday_4  weekday_5  weekday_6\n",
              "0   0        0 -1.334609  0.947345  ...          0          0          0          1\n",
              "1   0        0 -1.438475  0.895513  ...          0          0          0          1\n",
              "2   0        0 -1.438475  0.895513  ...          0          0          0          1\n",
              "3   0        0 -1.334609  0.636351  ...          0          0          0          1\n",
              "4   0        0 -1.334609  0.636351  ...          0          0          0          1\n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFXhUrU9895a",
        "colab_type": "text"
      },
      "source": [
        "### Split into training,  testing and validation set\n",
        "The data consists of entries of how many bikes are rented at one specific hour of the day. The total number of entries in the hour.csv is 17.379, which means divided by 24 there are datapoints for approximatly 724 days.\n",
        "\n",
        "The last 21 days (3%) are used as testing data.\n",
        "\n",
        "Of the remaining days, 60 days (8.5%) are used as validation data.\n",
        "\n",
        "The training data consists of 643 days."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJMWC_GmfUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = rides[-21*24:]\n",
        "rides = rides[:-21*24]\n",
        "\n",
        "validation_data = rides[-60*24:]\n",
        "rides = rides[:-60*24]\n",
        "\n",
        "train_data = rides\n",
        "\n",
        "target_fields = ['cnt']\n",
        "\n",
        "features_train, targets_train = train_data.drop(target_fields, axis=1), train_data[target_fields]\n",
        "features_validation, targets_validation = validation_data.drop(target_fields, axis=1), validation_data[target_fields]\n",
        "features_test, targets_test = test_data.drop(target_fields, axis=1), test_data[target_fields]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiIjayNCsbK3",
        "colab_type": "text"
      },
      "source": [
        "## Network architecture\n",
        "I define the necessary parts of the architecture and try them out before handing over to tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQqLWSXY44AG",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOF76Y_AAWOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameter = {'learning_rate': 0.01, 'hidden_nodes': 25, 'epochs': 4000, 'batch_size': 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9EJaIYW2czS",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg8SuRfrsu4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class BikeSharingModel(nn.Module):\n",
        "  def __init__(self, input_nodes, hidden_nodes):\n",
        "    super(BikeSharingModel, self).__init__()\n",
        "    self.fc_1 = nn.Linear(input_nodes, hidden_nodes)\n",
        "    self.fc_2 = nn.Linear(hidden_nodes, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc_1(x)\n",
        "    x = torch.sigmoid(x)\n",
        "    x = self.fc_2(x)\n",
        "\n",
        "    return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VSPjJCKvnTf",
        "colab_type": "code",
        "outputId": "5b74460b-418c-41e3-f72f-62726806d468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "input_nodes = features_train.shape[1]\n",
        "\n",
        "bikeSharingModel = BikeSharingModel(input_nodes, hyperparameter['hidden_nodes'])\n",
        "bikeSharingModel"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BikeSharingModel(\n",
              "  (fc_1): Linear(in_features=56, out_features=25, bias=True)\n",
              "  (fc_2): Linear(in_features=25, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fo4exhg2SUE",
        "colab_type": "text"
      },
      "source": [
        "### Loss-function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4n459Jd-IVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuqGV4br2vfA",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYnYWI4O_yOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(bikeSharingModel.parameters(), lr=hyperparameter['learning_rate'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg8BvTPN21Zn",
        "colab_type": "text"
      },
      "source": [
        "## Train, validate and test/inference\n",
        "Training is done with a batch size of random training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lci88lLVTmd5",
        "colab_type": "code",
        "outputId": "d04bf96a-feff-4fc8-8f67-8d3164cc43e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        }
      },
      "source": [
        "# preparing for using tune\n",
        "!pip install ray\n",
        "!pip uninstall -y pyarrow\n",
        "# cleanup tune log dir if exists\n",
        "!rm -rf tune_logs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/21/de080b8458de41fd8ac20dd96547418c0ed94eab4359e5885f4041d61337/ray-0.7.3-cp36-cp36m-manylinux1_x86_64.whl (48.5MB)\n",
            "\u001b[K     |████████████████████████████████| 48.5MB 1.3MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.8.0 (from ray)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray) (3.6.4)\n",
            "Collecting colorama (from ray)\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Collecting redis (from ray)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray) (7.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from ray) (1.16.4)\n",
            "Collecting funcsigs (from ray)\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray) (41.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray) (1.8.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray) (7.2.0)\n",
            "Installing collected packages: protobuf, colorama, redis, funcsigs, ray\n",
            "  Found existing installation: protobuf 3.7.1\n",
            "    Uninstalling protobuf-3.7.1:\n",
            "      Successfully uninstalled protobuf-3.7.1\n",
            "Successfully installed colorama-0.4.1 funcsigs-1.0.2 protobuf-3.9.1 ray-0.7.3 redis-3.3.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Uninstalling pyarrow-0.14.1:\n",
            "  Successfully uninstalled pyarrow-0.14.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIw-zHyYBKOU",
        "colab_type": "code",
        "outputId": "dea3f419-b2f5-4e57-d9cd-61d5687a25ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from ray import tune\n",
        "\n",
        "def train_validate_and_test_with_tune_tracking(features_train, targets_train, features_validation, targets_validation, features_test, targets_test, hyperparameter, with_tune_tracking=False):\n",
        "  input_nodes = features_train.shape[1]\n",
        "  bikeSharingModel = BikeSharingModel(input_nodes, hyperparameter['hidden_nodes'])\n",
        "  optimizer = optim.Adam(bikeSharingModel.parameters(), lr=hyperparameter['learning_rate'])\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  train_losses, validation_losses = [], []\n",
        "  for epoch in range(1, hyperparameter['epochs']+1):\n",
        "    batch_indices = np.random.choice(features_train.index, size=hyperparameter['batch_size'])\n",
        "    features = torch.tensor(features_train.iloc[batch_indices].values).float()\n",
        "    targets = torch.tensor(targets_train.iloc[batch_indices].values).float()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = bikeSharingModel(features)\n",
        "\n",
        "    loss = criterion(output, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # validate\n",
        "    with torch.no_grad():\n",
        "      bikeSharingModel.eval()\n",
        "      output_validation = bikeSharingModel(torch.tensor(features_validation.values).float())\n",
        "      loss_validation = criterion(output_validation, torch.tensor(targets_validation.values).float())\n",
        "\n",
        "    bikeSharingModel.train()\n",
        "\n",
        "    validation_losses.append(loss_validation.item())\n",
        "\n",
        "    # tune tracking\n",
        "    if with_tune_tracking:\n",
        "      tune.track.log(validation_loss_metric=loss_validation.item())\n",
        "\n",
        "    # output\n",
        "    if not with_tune_tracking:\n",
        "      sys.stdout.write(\"\\rEpoch: {} Training loss: {} Validation loss: {}\".format(epoch, loss, loss_validation))\n",
        "      sys.stdout.flush()\n",
        "\n",
        "  # test\n",
        "  with torch.no_grad():\n",
        "    bikeSharingModel.eval()\n",
        "    output_test = bikeSharingModel(torch.tensor(features_test.values).float())\n",
        "    test_loss = criterion(output_test, torch.tensor(targets_test.values).float())\n",
        "    bikeSharingModel.train()\n",
        "\n",
        "  # tune tracking\n",
        "  if with_tune_tracking:\n",
        "     tune.track.log(train_losses_metric=train_losses.item())\n",
        "\n",
        "  # output\n",
        "  if not with_tune_tracking:\n",
        "    print(\"Test loss \", test_loss.item())\n",
        "\n",
        "  return train_losses, validation_losses, test_loss, output_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-02f3a5f8eecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_validate_and_test_with_tune_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_tune_tracking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ray/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"pyarrow\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     raise ImportError(\"Ray must be imported before pyarrow because Ray \"\n\u001b[0m\u001b[1;32m     10\u001b[0m                       \u001b[0;34m\"requires a specific version of pyarrow (which is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \"packaged along with Ray).\")\n",
            "\u001b[0;31mImportError\u001b[0m: Ray must be imported before pyarrow because Ray requires a specific version of pyarrow (which is packaged along with Ray).",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmcszdFmXhc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(train_losses, validation_losses, test_loss, output_test, targets_test):\n",
        "  plt.plot(train_losses, label='Training loss')\n",
        "  plt.plot(validation_losses, label='Validation loss')\n",
        "  plt.legend()\n",
        "  _ = plt.ylim(0, 0.75)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(8,4))\n",
        "\n",
        "  mean, std = feature_scaling_store['cnt']\n",
        "  ax.plot(output_test.numpy()*std + mean, label='Prediction')\n",
        "  ax.plot((targets_test['cnt']*std + mean).values, label='Data')\n",
        "  ax.set_xlim(right=len(output_test))\n",
        "  ax.legend()\n",
        "  dates = pd.to_datetime(rides_origin.iloc[test_data.index]['dteday'])\n",
        "  dates = dates.apply(lambda d: d.strftime('%b %d'))\n",
        "  ax.set_xticks(np.arange(len(dates))[12::24])\n",
        "  _ = ax.set_xticklabels(dates[12::24], rotation=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0JgM0Oq3gX8",
        "colab_type": "text"
      },
      "source": [
        "## Manual hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTAf7blYw9vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameter = {'learning_rate': 0.01, 'hidden_nodes': 25, 'epochs': 4000, 'batch_size': 1}\n",
        "train_losses, validation_losses, test_loss, output_test = train_validate_and_test_with_tune_tracking(features_train, targets_train, features_validation, targets_validation, features_test, targets_test, hyperparameter)\n",
        "plot(train_losses, validation_losses, test_loss, output_test, targets_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFe-RycNCorU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try other hyperparameter\n",
        "hyperparameter = {'learning_rate': 0.5, 'hidden_nodes': 25, 'epochs': 4000, 'batch_size': 128}\n",
        "train_losses, validation_losses, test_loss, output_test = train_validate_and_test_with_tune_tracking(features_train, targets_train, features_validation, targets_validation, features_test, targets_test, hyperparameter)\n",
        "plot(train_losses, validation_losses, test_loss, output_test, targets_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCovkuS8Q7Ug",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparamter tuning with tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF08qStlWP0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_it(config):\n",
        "  train_validate_and_test_with_tune_tracking(features_train, targets_train, features_validation, targets_validation, features_test, targets_test, config, with_tune_tracking=True)\n",
        "\n",
        "tune_result = tune.run(tune_it,\n",
        "                   config={'learning_rate': tune.grid_search([0.01, 0.5, 0.4]),\n",
        "                            'hidden_nodes': tune.grid_search([15, 25, 30]),\n",
        "                            'epochs': 4,#4000,\n",
        "                            'batch_size': tune.grid_search([1, 128])\n",
        "                            },\n",
        "                   local_dir='tune_logs',\n",
        "                   verbose=0)\n",
        "\n",
        "print(\"Best config: \", tune_result.get_best_config(metric='mymetric'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K04-YyjXToq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tune_logs/tune_it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9-dmXi33EE0",
        "colab_type": "text"
      },
      "source": [
        "## Further steps/TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7WTb-tW2HQ-",
        "colab_type": "text"
      },
      "source": [
        "- test with adding field *workingday*\n",
        "- test with making field *holiday* categorical\n",
        "- test with delete field *year*\n",
        "- test with adding field *atemp*\n",
        "\n",
        "\n",
        "- check standard deviation\n",
        "- drop header in data\n",
        "- use GPU\n",
        "- add own dataloader\n",
        "- add dropout\n",
        "- transformation of tensor/dataframe for data sets is not dry\n",
        "\n",
        "\n",
        "- losses of this model differ from losses of original implementation with same hyperparameter\n",
        "- in the original project, the weights of the network are initialized\n",
        "\n",
        "\n",
        "- change tune from grid search to bayesian optimization and write comments\n",
        "- try different bag sizes for test/validation/train sets\n",
        "- build fcn best practice by Andrej Karpathy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNDTBEwcwisu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}